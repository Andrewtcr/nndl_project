{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9ff412d8e71f429380b4fb6717f48012": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ba77d6cb9e134d74b7c74342f124c2d1",
              "IPY_MODEL_7cf29c6d7fa64f92ae08fcb89c9c0b85",
              "IPY_MODEL_69f5bbbc57784332b99c5b026b553e81"
            ],
            "layout": "IPY_MODEL_e13e1eb11b464637997218080d844346"
          }
        },
        "ba77d6cb9e134d74b7c74342f124c2d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a34e5864481494cac1e85f634c7feae",
            "placeholder": "​",
            "style": "IPY_MODEL_942b3473805b4539ab9f1c1aca35f9ce",
            "value": "Downloading: 100%"
          }
        },
        "7cf29c6d7fa64f92ae08fcb89c9c0b85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7add0b6f0bab4319a76d558ee14cd39a",
            "max": 345636463,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_60e252ffeee044be84efb49f2074412d",
            "value": 345636463
          }
        },
        "69f5bbbc57784332b99c5b026b553e81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8200660003bf4b468d321ddec15f826b",
            "placeholder": "​",
            "style": "IPY_MODEL_7740d29d85ec4cea8cbce35a8eb794d9",
            "value": " 346M/346M [00:09&lt;00:00, 72.7MB/s]"
          }
        },
        "e13e1eb11b464637997218080d844346": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a34e5864481494cac1e85f634c7feae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "942b3473805b4539ab9f1c1aca35f9ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7add0b6f0bab4319a76d558ee14cd39a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60e252ffeee044be84efb49f2074412d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8200660003bf4b468d321ddec15f826b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7740d29d85ec4cea8cbce35a8eb794d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "43e1ebd83f3747a68a69f201cd71587d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_718a39801a054effb24fdc0f1c492d00",
              "IPY_MODEL_c2f9dcf8ad614c368e001e3db99024f9",
              "IPY_MODEL_c9f53a4730574d97a02d502968662bee"
            ],
            "layout": "IPY_MODEL_592196b3b56c41fb81cc379388a1fb2c"
          }
        },
        "718a39801a054effb24fdc0f1c492d00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97d40f9434184feab92977e490366b15",
            "placeholder": "​",
            "style": "IPY_MODEL_28c0cec9abc445c296927d5920e0ab80",
            "value": "Downloading builder script: "
          }
        },
        "c2f9dcf8ad614c368e001e3db99024f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_20feac95b5a5456fbe08c73cf99e2331",
            "max": 1652,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eb2d6191d2ea45a68c59d689fef02b26",
            "value": 1652
          }
        },
        "c9f53a4730574d97a02d502968662bee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_35a509ece83745cfbc29ac455092a354",
            "placeholder": "​",
            "style": "IPY_MODEL_0f2f17cd4c394ae58403558a54949cfb",
            "value": " 4.21k/? [00:00&lt;00:00, 213kB/s]"
          }
        },
        "592196b3b56c41fb81cc379388a1fb2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97d40f9434184feab92977e490366b15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28c0cec9abc445c296927d5920e0ab80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "20feac95b5a5456fbe08c73cf99e2331": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb2d6191d2ea45a68c59d689fef02b26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "35a509ece83745cfbc29ac455092a354": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f2f17cd4c394ae58403558a54949cfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "zip_ref = zipfile.ZipFile(\"/content/drive/My Drive/subclass_training_data.zip\", 'r')\n",
        "zip_ref.extractall(\"/tmp\")\n",
        "zip_ref.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RfJwfudHCnNh",
        "outputId": "f2ee94ff-1f82-4b00-98e2-32477a07a602"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcz4jgulDFlK",
        "outputId": "8c98e173-3d15-4d6b-f1ba-63ce9535e0a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 30.1 MB/s \n",
            "\u001b[?25hCollecting datasets\n",
            "  Downloading datasets-2.7.1-py3-none-any.whl (451 kB)\n",
            "\u001b[K     |████████████████████████████████| 451 kB 74.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.2)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 76.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 66.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (2022.11.0)\n",
            "Collecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets) (3.8.3)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.1.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[K     |████████████████████████████████| 212 kB 81.1 MB/s \n",
            "\u001b[?25hCollecting multiprocess\n",
            "  Downloading multiprocess-0.70.14-py38-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 57.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: dill<0.3.7 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (2.1.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.8.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (22.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (6.0.3)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 80.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2022.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Installing collected packages: urllib3, xxhash, tokenizers, responses, multiprocess, huggingface-hub, transformers, datasets\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "Successfully installed datasets-2.7.1 huggingface-hub-0.11.1 multiprocess-0.70.14 responses-0.18.0 tokenizers-0.13.2 transformers-4.25.1 urllib3-1.25.11 xxhash-3.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309,
          "referenced_widgets": [
            "9ff412d8e71f429380b4fb6717f48012",
            "ba77d6cb9e134d74b7c74342f124c2d1",
            "7cf29c6d7fa64f92ae08fcb89c9c0b85",
            "69f5bbbc57784332b99c5b026b553e81",
            "e13e1eb11b464637997218080d844346",
            "4a34e5864481494cac1e85f634c7feae",
            "942b3473805b4539ab9f1c1aca35f9ce",
            "7add0b6f0bab4319a76d558ee14cd39a",
            "60e252ffeee044be84efb49f2074412d",
            "8200660003bf4b468d321ddec15f826b",
            "7740d29d85ec4cea8cbce35a8eb794d9",
            "43e1ebd83f3747a68a69f201cd71587d",
            "718a39801a054effb24fdc0f1c492d00",
            "c2f9dcf8ad614c368e001e3db99024f9",
            "c9f53a4730574d97a02d502968662bee",
            "592196b3b56c41fb81cc379388a1fb2c",
            "97d40f9434184feab92977e490366b15",
            "28c0cec9abc445c296927d5920e0ab80",
            "20feac95b5a5456fbe08c73cf99e2331",
            "eb2d6191d2ea45a68c59d689fef02b26",
            "35a509ece83745cfbc29ac455092a354",
            "0f2f17cd4c394ae58403558a54949cfb"
          ]
        },
        "id": "NAY4xAlnBYl_",
        "outputId": "a28d147e-6915-4d7c-ebd3-b9a98d901fca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=8x8 at 0x7FF0BBE27F10>, 'label': 0}\n",
            "['eft', 'oystercatcher, oyster catcher', 'green lizard, Lacerta viridis', 'junco, snowbird', 'Chihuahua', 'Sealyham terrier, Sealyham', 'basset, basset hound', 'pelican', 'soft-coated wheaten terrier', 'bulbul', 'loggerhead, loggerhead turtle, Caretta caretta', 'thunder snake, worm snake, Carphophis amoenus', 'American chameleon, anole, Anolis carolinensis', 'African crocodile, Nile crocodile, Crocodylus niloticus', 'toy terrier', 'triceratops', 'bald eagle, American eagle, Haliaeetus leucocephalus', 'Dandie Dinmont, Dandie Dinmont terrier', 'European gallinule, Porphyrio porphyrio', 'cock', 'alligator lizard', 'Blenheim spaniel', 'jay', 'silky terrier, Sydney silky', 'redshank, Tringa totanus', 'red-backed sandpiper, dunlin, Erolia alpina', 'ruddy turnstone, Arenaria interpres', 'giant schnauzer', 'Pekinese, Pekingese, Peke', 'Lhasa, Lhasa apso', 'brambling, Fringilla montifringilla', 'robin, American robin, Turdus migratorius', 'beagle', 'vulture', 'miniature schnauzer', 'American coot, marsh hen, mud hen, water hen, Fulica americana', 'whiptail, whiptail lizard', 'Airedale, Airedale terrier', 'frilled lizard, Chlamydosaurus kingi', 'ostrich, Struthio camelus', 'Afghan hound, Afghan', 'Shih-Tzu', 'European fire salamander, Salamandra salamandra', 'Scotch terrier, Scottish terrier, Scottie', 'papillon', 'axolotl, mud puppy, Ambystoma mexicanum', 'leatherback turtle, leatherback, leathery turtle, Dermochelys coriacea', 'West Highland white terrier', 'house finch, linnet, Carpodacus mexicanus', 'hen', 'cairn, cairn terrier', 'American alligator, Alligator mississipiensis', 'Rhodesian ridgeback', 'chickadee', 'albatross, mollymawk', 'bullfrog, Rana catesbeiana', 'tree frog, tree-frog', 'ringneck snake, ring-necked snake, ring snake', 'Tibetan terrier, chrysanthemum dog', 'water ouzel, dipper', 'bloodhound, sleuthhound', 'Boston bull, Boston terrier', 'black grouse', 'terrapin', 'common newt, Triturus vulgaris', 'great grey owl, great gray owl, Strix nebulosa', 'mud turtle', 'standard schnauzer', 'ptarmigan', 'Lakeland terrier', 'goldfinch, Carduelis carduelis', 'Australian terrier', 'magpie', 'bustard', 'common iguana, iguana, Iguana iguana', 'Gila monster, Heloderma suspectum', 'Komodo dragon, Komodo lizard, dragon lizard, giant lizard, Varanus komodoensis', 'indigo bunting, indigo finch, indigo bird, Passerina cyanea', 'dowitcher', 'green snake, grass snake', 'agama', 'hognose snake, puff adder, sand viper', 'African chameleon, Chamaeleo chamaeleon', 'banded gecko', 'Maltese dog, Maltese terrier, Maltese', 'Japanese spaniel', 'king penguin, Aptenodytes patagonica', 'tailed frog, bell toad, ribbed toad, tailed toad, Ascaphus trui', 'spotted salamander, Ambystoma maculatum']\n",
            "{0: 'eft', 1: 'oystercatcher, oyster catcher', 2: 'green lizard, Lacerta viridis', 3: 'junco, snowbird', 4: 'Chihuahua', 5: 'Sealyham terrier, Sealyham', 6: 'basset, basset hound', 7: 'pelican', 8: 'soft-coated wheaten terrier', 9: 'bulbul', 10: 'loggerhead, loggerhead turtle, Caretta caretta', 11: 'thunder snake, worm snake, Carphophis amoenus', 12: 'American chameleon, anole, Anolis carolinensis', 13: 'African crocodile, Nile crocodile, Crocodylus niloticus', 14: 'toy terrier', 15: 'triceratops', 16: 'bald eagle, American eagle, Haliaeetus leucocephalus', 17: 'Dandie Dinmont, Dandie Dinmont terrier', 18: 'European gallinule, Porphyrio porphyrio', 19: 'cock', 20: 'alligator lizard', 21: 'Blenheim spaniel', 22: 'jay', 23: 'silky terrier, Sydney silky', 24: 'redshank, Tringa totanus', 25: 'red-backed sandpiper, dunlin, Erolia alpina', 26: 'ruddy turnstone, Arenaria interpres', 27: 'giant schnauzer', 28: 'Pekinese, Pekingese, Peke', 29: 'Lhasa, Lhasa apso', 30: 'brambling, Fringilla montifringilla', 31: 'robin, American robin, Turdus migratorius', 32: 'beagle', 33: 'vulture', 34: 'miniature schnauzer', 35: 'American coot, marsh hen, mud hen, water hen, Fulica americana', 36: 'whiptail, whiptail lizard', 37: 'Airedale, Airedale terrier', 38: 'frilled lizard, Chlamydosaurus kingi', 39: 'ostrich, Struthio camelus', 40: 'Afghan hound, Afghan', 41: 'Shih-Tzu', 42: 'European fire salamander, Salamandra salamandra', 43: 'Scotch terrier, Scottish terrier, Scottie', 44: 'papillon', 45: 'axolotl, mud puppy, Ambystoma mexicanum', 46: 'leatherback turtle, leatherback, leathery turtle, Dermochelys coriacea', 47: 'West Highland white terrier', 48: 'house finch, linnet, Carpodacus mexicanus', 49: 'hen', 50: 'cairn, cairn terrier', 51: 'American alligator, Alligator mississipiensis', 52: 'Rhodesian ridgeback', 53: 'chickadee', 54: 'albatross, mollymawk', 55: 'bullfrog, Rana catesbeiana', 56: 'tree frog, tree-frog', 57: 'ringneck snake, ring-necked snake, ring snake', 58: 'Tibetan terrier, chrysanthemum dog', 59: 'water ouzel, dipper', 60: 'bloodhound, sleuthhound', 61: 'Boston bull, Boston terrier', 62: 'black grouse', 63: 'terrapin', 64: 'common newt, Triturus vulgaris', 65: 'great grey owl, great gray owl, Strix nebulosa', 66: 'mud turtle', 67: 'standard schnauzer', 68: 'ptarmigan', 69: 'Lakeland terrier', 70: 'goldfinch, Carduelis carduelis', 71: 'Australian terrier', 72: 'magpie', 73: 'bustard', 74: 'common iguana, iguana, Iguana iguana', 75: 'Gila monster, Heloderma suspectum', 76: 'Komodo dragon, Komodo lizard, dragon lizard, giant lizard, Varanus komodoensis', 77: 'indigo bunting, indigo finch, indigo bird, Passerina cyanea', 78: 'dowitcher', 79: 'green snake, grass snake', 80: 'agama', 81: 'hognose snake, puff adder, sand viper', 82: 'African chameleon, Chamaeleo chamaeleon', 83: 'banded gecko', 84: 'Maltese dog, Maltese terrier, Maltese', 85: 'Japanese spaniel', 86: 'king penguin, Aptenodytes patagonica', 87: 'tailed frog, bell toad, ribbed toad, tailed toad, Ascaphus trui', 88: 'spotted salamander, Ambystoma maculatum'}\n",
            "{'eft': 0, 'oystercatcher, oyster catcher': 1, 'green lizard, Lacerta viridis': 2, 'junco, snowbird': 3, 'Chihuahua': 4, 'Sealyham terrier, Sealyham': 5, 'basset, basset hound': 6, 'pelican': 7, 'soft-coated wheaten terrier': 8, 'bulbul': 9, 'loggerhead, loggerhead turtle, Caretta caretta': 10, 'thunder snake, worm snake, Carphophis amoenus': 11, 'American chameleon, anole, Anolis carolinensis': 12, 'African crocodile, Nile crocodile, Crocodylus niloticus': 13, 'toy terrier': 14, 'triceratops': 15, 'bald eagle, American eagle, Haliaeetus leucocephalus': 16, 'Dandie Dinmont, Dandie Dinmont terrier': 17, 'European gallinule, Porphyrio porphyrio': 18, 'cock': 19, 'alligator lizard': 20, 'Blenheim spaniel': 21, 'jay': 22, 'silky terrier, Sydney silky': 23, 'redshank, Tringa totanus': 24, 'red-backed sandpiper, dunlin, Erolia alpina': 25, 'ruddy turnstone, Arenaria interpres': 26, 'giant schnauzer': 27, 'Pekinese, Pekingese, Peke': 28, 'Lhasa, Lhasa apso': 29, 'brambling, Fringilla montifringilla': 30, 'robin, American robin, Turdus migratorius': 31, 'beagle': 32, 'vulture': 33, 'miniature schnauzer': 34, 'American coot, marsh hen, mud hen, water hen, Fulica americana': 35, 'whiptail, whiptail lizard': 36, 'Airedale, Airedale terrier': 37, 'frilled lizard, Chlamydosaurus kingi': 38, 'ostrich, Struthio camelus': 39, 'Afghan hound, Afghan': 40, 'Shih-Tzu': 41, 'European fire salamander, Salamandra salamandra': 42, 'Scotch terrier, Scottish terrier, Scottie': 43, 'papillon': 44, 'axolotl, mud puppy, Ambystoma mexicanum': 45, 'leatherback turtle, leatherback, leathery turtle, Dermochelys coriacea': 46, 'West Highland white terrier': 47, 'house finch, linnet, Carpodacus mexicanus': 48, 'hen': 49, 'cairn, cairn terrier': 50, 'American alligator, Alligator mississipiensis': 51, 'Rhodesian ridgeback': 52, 'chickadee': 53, 'albatross, mollymawk': 54, 'bullfrog, Rana catesbeiana': 55, 'tree frog, tree-frog': 56, 'ringneck snake, ring-necked snake, ring snake': 57, 'Tibetan terrier, chrysanthemum dog': 58, 'water ouzel, dipper': 59, 'bloodhound, sleuthhound': 60, 'Boston bull, Boston terrier': 61, 'black grouse': 62, 'terrapin': 63, 'common newt, Triturus vulgaris': 64, 'great grey owl, great gray owl, Strix nebulosa': 65, 'mud turtle': 66, 'standard schnauzer': 67, 'ptarmigan': 68, 'Lakeland terrier': 69, 'goldfinch, Carduelis carduelis': 70, 'Australian terrier': 71, 'magpie': 72, 'bustard': 73, 'common iguana, iguana, Iguana iguana': 74, 'Gila monster, Heloderma suspectum': 75, 'Komodo dragon, Komodo lizard, dragon lizard, giant lizard, Varanus komodoensis': 76, 'indigo bunting, indigo finch, indigo bird, Passerina cyanea': 77, 'dowitcher': 78, 'green snake, grass snake': 79, 'agama': 80, 'hognose snake, puff adder, sand viper': 81, 'African chameleon, Chamaeleo chamaeleon': 82, 'banded gecko': 83, 'Maltese dog, Maltese terrier, Maltese': 84, 'Japanese spaniel': 85, 'king penguin, Aptenodytes patagonica': 86, 'tailed frog, bell toad, ribbed toad, tailed toad, Ascaphus trui': 87, 'spotted salamander, Ambystoma maculatum': 88}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/346M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9ff412d8e71f429380b4fb6717f48012"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at google/vit-base-patch16-224-in21k were not used when initializing ViTForImageClassification: ['pooler.dense.weight', 'pooler.dense.bias']\n",
            "- This IS expected if you are initializing ViTForImageClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing ViTForImageClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'height': 224, 'width': 224}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-c353721c81c5>:123: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
            "  metric = load_metric(\"accuracy\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/1.65k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "43e1ebd83f3747a68a69f201cd71587d"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from transformers import ViTFeatureExtractor, ViTForImageClassification, TrainingArguments, Trainer\n",
        "import numpy as np\n",
        "from datasets import Image, Dataset, load_metric\n",
        "from torchvision.transforms import (CenterCrop, \n",
        "                                    Compose, \n",
        "                                    Normalize, \n",
        "                                    RandomHorizontalFlip,\n",
        "                                    RandomResizedCrop, \n",
        "                                    Resize, \n",
        "                                    ToTensor)                        \n",
        "from torch.utils.data import DataLoader\n",
        "import torch\n",
        "import os\n",
        "\n",
        "\n",
        "DATASET_DIR = '/tmp/subclass_training_data/train'\n",
        "\n",
        "\n",
        "# Hangs like hell and i dont know why\n",
        "# dataset = load_dataset('imagefolder', data_dir='D:/Homework Assignments/NNDL/project/subclass_training_data', cache_dir='./')\n",
        "\n",
        "training_images = []\n",
        "training_labels = []\n",
        "label_names = []\n",
        "\n",
        "directory = os.fsencode(DATASET_DIR)\n",
        "\n",
        "for folder in os.listdir(directory):\n",
        "    folder_name = os.fsdecode(folder)\n",
        "    label_names.append(folder_name)\n",
        "    for file in os.listdir(os.fsencode(f'{DATASET_DIR}/{folder_name}')):\n",
        "        # print(os.fsdecode(file))\n",
        "\n",
        "        filename = os.fsdecode(file)\n",
        "        img_path = f'{DATASET_DIR}/{folder_name}/{filename}'\n",
        "\n",
        "        training_images.append(img_path)\n",
        "        training_labels.append(label_names.index(folder_name))\n",
        "\n",
        "dataset = Dataset.from_dict({'image': training_images, 'label': training_labels}).cast_column(\"image\", Image())\n",
        "\n",
        "dataset.shuffle(seed=42)\n",
        "print(dataset[0])\n",
        "print(label_names)\n",
        "\n",
        "\n",
        "### FROM VIT CARD https://huggingface.co/google/vit-base-patch16-224 ###\n",
        "# url = 'http://images.cocodataset.org/val2017/000000039769.jpg'\n",
        "# image = dataset[0]['image']\n",
        "\n",
        "splits = dataset.train_test_split(test_size=0.1)\n",
        "train_ds = splits['train']\n",
        "val_ds = splits['test']\n",
        "\n",
        "# print(train_ds['label'])\n",
        "\n",
        "id2label = {id:label for id, label in enumerate(label_names)}\n",
        "label2id = {label:id for id, label in id2label.items()}\n",
        "\n",
        "print(id2label)\n",
        "print(label2id)\n",
        "\n",
        "feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-base-patch16-224')\n",
        "model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224-in21k',\n",
        "                                                  num_labels=89,\n",
        "                                                  id2label=id2label,\n",
        "                                                  label2id=label2id)\n",
        "# inputs = feature_extractor(images=image, return_tensors=\"pt\")\n",
        "\n",
        "print(feature_extractor.size)\n",
        "resize_seq = (feature_extractor.size['height'], feature_extractor.size['width'])\n",
        "\n",
        "normalize = Normalize(mean=feature_extractor.image_mean, std=feature_extractor.image_std)\n",
        "_train_transforms = Compose(\n",
        "        [\n",
        "            RandomResizedCrop(resize_seq),\n",
        "            RandomHorizontalFlip(),\n",
        "            ToTensor(),\n",
        "            normalize,\n",
        "        ]\n",
        "    )\n",
        "\n",
        "_val_transforms = Compose(\n",
        "        [\n",
        "            Resize(resize_seq),\n",
        "            CenterCrop(resize_seq),\n",
        "            ToTensor(),\n",
        "            normalize,\n",
        "        ]\n",
        "    )\n",
        "\n",
        "def train_transforms(examples):\n",
        "    examples['pixel_values'] = [_train_transforms(image.convert(\"RGB\")) for image in examples['image']]\n",
        "    return examples\n",
        "\n",
        "def val_transforms(examples):\n",
        "    examples['pixel_values'] = [_val_transforms(image.convert(\"RGB\")) for image in examples['image']]\n",
        "    return examples\n",
        "\n",
        "# Set the transforms\n",
        "train_ds.set_transform(train_transforms)\n",
        "val_ds.set_transform(val_transforms)\n",
        "\n",
        "# print(train_ds[:2])\n",
        "\n",
        "metric_name = \"accuracy\"\n",
        "\n",
        "args = TrainingArguments(\n",
        "    'nndl_checkpoints_etc',\n",
        "    save_strategy=\"epoch\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=10,\n",
        "    per_device_eval_batch_size=4,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=metric_name,\n",
        "    logging_dir='logs',\n",
        "    remove_unused_columns=False,\n",
        ")\n",
        "     \n",
        "metric = load_metric(\"accuracy\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    return metric.compute(predictions=predictions, references=labels)\n",
        "\n",
        "def collate_fn(examples):\n",
        "    pixel_values = torch.stack([example[\"pixel_values\"] for example in examples])\n",
        "    labels = torch.tensor([example[\"label\"] for example in examples])\n",
        "    return {\"pixel_values\": pixel_values, \"labels\": labels}\n",
        "\n",
        "trainer = Trainer(\n",
        "    model,\n",
        "    args,\n",
        "    train_dataset=train_ds,\n",
        "    eval_dataset=val_ds,\n",
        "    data_collator=collate_fn,\n",
        "    compute_metrics=compute_metrics,\n",
        "    tokenizer=feature_extractor,\n",
        ")\n",
        "\n",
        "# trainer.train()\n",
        "\n",
        "\n",
        "# train_dataloader = DataLoader(train_ds, collate_fn=collate_fn, batch_size=4)\n",
        "\n",
        "# batch = next(iter(train_dataloader))\n",
        "# for k,v in batch.items():\n",
        "#   if isinstance(v, torch.Tensor):\n",
        "#     print(k, v.shape)\n",
        "\n",
        "\n",
        "\n",
        "# outputs = model(**inputs)\n",
        "# logits = outputs.logits\n",
        "# # model predicts one of the 1000 ImageNet classes\n",
        "# predicted_class_idx = logits.argmax(-1).item()\n",
        "# print(\"Predicted class:\", model.config.id2label[predicted_class_idx])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "args = TrainingArguments(\n",
        "    'nndl_checkpoints_etc',\n",
        "    save_strategy=\"epoch\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=10,\n",
        "    per_device_eval_batch_size=4,\n",
        "    num_train_epochs=4,\n",
        "    weight_decay=0.01,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=metric_name,\n",
        "    logging_dir='logs',\n",
        "    remove_unused_columns=False,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model,\n",
        "    args,\n",
        "    train_dataset=train_ds,\n",
        "    eval_dataset=val_ds,\n",
        "    data_collator=collate_fn,\n",
        "    compute_metrics=compute_metrics,\n",
        "    tokenizer=feature_extractor,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3DpqD4MLKmzs",
        "outputId": "b5ed0c7b-6ac5-4cbe-a26a-b30967fd91b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 9829\n",
            "  Num Epochs = 4\n",
            "  Instantaneous batch size per device = 10\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 10\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 3932\n",
            "  Number of trainable parameters = 85867097\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3932' max='3932' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3932/3932 26:55, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>3.872200</td>\n",
              "      <td>3.655452</td>\n",
              "      <td>0.172004</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>3.649800</td>\n",
              "      <td>3.491529</td>\n",
              "      <td>0.207685</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>3.555700</td>\n",
              "      <td>3.392200</td>\n",
              "      <td>0.233303</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>3.486500</td>\n",
              "      <td>3.354999</td>\n",
              "      <td>0.240622</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 1093\n",
            "  Batch size = 4\n",
            "Saving model checkpoint to nndl_checkpoints_etc/checkpoint-983\n",
            "Configuration saved in nndl_checkpoints_etc/checkpoint-983/config.json\n",
            "Model weights saved in nndl_checkpoints_etc/checkpoint-983/pytorch_model.bin\n",
            "Image processor saved in nndl_checkpoints_etc/checkpoint-983/preprocessor_config.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1093\n",
            "  Batch size = 4\n",
            "Saving model checkpoint to nndl_checkpoints_etc/checkpoint-1966\n",
            "Configuration saved in nndl_checkpoints_etc/checkpoint-1966/config.json\n",
            "Model weights saved in nndl_checkpoints_etc/checkpoint-1966/pytorch_model.bin\n",
            "Image processor saved in nndl_checkpoints_etc/checkpoint-1966/preprocessor_config.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1093\n",
            "  Batch size = 4\n",
            "Saving model checkpoint to nndl_checkpoints_etc/checkpoint-2949\n",
            "Configuration saved in nndl_checkpoints_etc/checkpoint-2949/config.json\n",
            "Model weights saved in nndl_checkpoints_etc/checkpoint-2949/pytorch_model.bin\n",
            "Image processor saved in nndl_checkpoints_etc/checkpoint-2949/preprocessor_config.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1093\n",
            "  Batch size = 4\n",
            "Saving model checkpoint to nndl_checkpoints_etc/checkpoint-3932\n",
            "Configuration saved in nndl_checkpoints_etc/checkpoint-3932/config.json\n",
            "Model weights saved in nndl_checkpoints_etc/checkpoint-3932/pytorch_model.bin\n",
            "Image processor saved in nndl_checkpoints_etc/checkpoint-3932/preprocessor_config.json\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from nndl_checkpoints_etc/checkpoint-3932 (score: 0.24062214089661482).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=3932, training_loss=3.617821539163832, metrics={'train_runtime': 1616.0859, 'train_samples_per_second': 24.328, 'train_steps_per_second': 2.433, 'total_flos': 3.0490507191757455e+18, 'train_loss': 3.617821539163832, 'epoch': 4.0})"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "args = TrainingArguments(\n",
        "    'nndl_checkpoints_etc',\n",
        "    save_strategy=\"epoch\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=10,\n",
        "    per_device_eval_batch_size=4,\n",
        "    num_train_epochs=4,\n",
        "    weight_decay=0.01,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=metric_name,\n",
        "    logging_dir='logs',\n",
        "    remove_unused_columns=False,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model,\n",
        "    args,\n",
        "    train_dataset=train_ds,\n",
        "    eval_dataset=val_ds,\n",
        "    data_collator=collate_fn,\n",
        "    compute_metrics=compute_metrics,\n",
        "    tokenizer=feature_extractor,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Rn2MJY0rRI8z",
        "outputId": "42817cea-ac66-4f0f-fdbe-fe25fd365b88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 9829\n",
            "  Num Epochs = 4\n",
            "  Instantaneous batch size per device = 10\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 10\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 3932\n",
            "  Number of trainable parameters = 85867097\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3932' max='3932' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3932/3932 26:51, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>3.451200</td>\n",
              "      <td>3.300677</td>\n",
              "      <td>0.225069</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>3.268300</td>\n",
              "      <td>3.171093</td>\n",
              "      <td>0.249771</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>3.206300</td>\n",
              "      <td>3.078944</td>\n",
              "      <td>0.276304</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>3.167800</td>\n",
              "      <td>3.048329</td>\n",
              "      <td>0.283623</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 1093\n",
            "  Batch size = 4\n",
            "Saving model checkpoint to nndl_checkpoints_etc/checkpoint-983\n",
            "Configuration saved in nndl_checkpoints_etc/checkpoint-983/config.json\n",
            "Model weights saved in nndl_checkpoints_etc/checkpoint-983/pytorch_model.bin\n",
            "Image processor saved in nndl_checkpoints_etc/checkpoint-983/preprocessor_config.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1093\n",
            "  Batch size = 4\n",
            "Saving model checkpoint to nndl_checkpoints_etc/checkpoint-1966\n",
            "Configuration saved in nndl_checkpoints_etc/checkpoint-1966/config.json\n",
            "Model weights saved in nndl_checkpoints_etc/checkpoint-1966/pytorch_model.bin\n",
            "Image processor saved in nndl_checkpoints_etc/checkpoint-1966/preprocessor_config.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1093\n",
            "  Batch size = 4\n",
            "Saving model checkpoint to nndl_checkpoints_etc/checkpoint-2949\n",
            "Configuration saved in nndl_checkpoints_etc/checkpoint-2949/config.json\n",
            "Model weights saved in nndl_checkpoints_etc/checkpoint-2949/pytorch_model.bin\n",
            "Image processor saved in nndl_checkpoints_etc/checkpoint-2949/preprocessor_config.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1093\n",
            "  Batch size = 4\n",
            "Saving model checkpoint to nndl_checkpoints_etc/checkpoint-3932\n",
            "Configuration saved in nndl_checkpoints_etc/checkpoint-3932/config.json\n",
            "Model weights saved in nndl_checkpoints_etc/checkpoint-3932/pytorch_model.bin\n",
            "Image processor saved in nndl_checkpoints_etc/checkpoint-3932/preprocessor_config.json\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from nndl_checkpoints_etc/checkpoint-3932 (score: 0.2836230558096981).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=3932, training_loss=3.2615244371602397, metrics={'train_runtime': 1611.8935, 'train_samples_per_second': 24.391, 'train_steps_per_second': 2.439, 'total_flos': 3.0490507191757455e+18, 'train_loss': 3.2615244371602397, 'epoch': 4.0})"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    }
  ]
}